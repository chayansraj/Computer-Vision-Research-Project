{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50  import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore FutureWarning from numpy\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "\n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";\n",
    "\n",
    "# Allow growth of GPU memory, otherwise it will always look like all the memory is being used\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagenerator = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagenerator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.80,1.20],\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2600 images belonging to 2 classes.\n",
      "Found 870 images belonging to 2 classes.\n",
      "Found 864 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# load and iterate training dataset\n",
    "train_data = datagenerator.flow_from_directory('../train/', \n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224), \n",
    "    batch_size=64, \n",
    "    shuffle=False)\n",
    "\n",
    "# load and iterate validation dataset\n",
    "val_data = datagenerator.flow_from_directory('../valid/', \n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64, \n",
    "    shuffle=False)\n",
    "\n",
    "# load and iterate test dataset\n",
    "test_data = datagenerator.flow_from_directory('../test/', \n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64, \n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.activations import relu, softmax, sigmoid, swish\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = VGG16(input_shape=(224,224,3),\n",
    "                                include_top=False,\n",
    "                                weights=\"imagenet\")\n",
    "\n",
    "# Some weights in later layers are unfreezed\n",
    "for layer in pre_trained_model.layers[:-5]:\n",
    "    layer.trainable=False\n",
    "\n",
    "tf.random.set_seed(2022)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    pre_trained_model,\n",
    "    GlobalAveragePooling2D(),    \n",
    "    Dense(512,activation=\"swish\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(256,activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),  \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=RMSprop(learning_rate=1e-4),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer= RMSprop(learning_rate=0.001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=50,\n",
    "    epochs=5,\n",
    "    validation_data=val_data,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researchkernel",
   "language": "python",
   "name": "researchkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
