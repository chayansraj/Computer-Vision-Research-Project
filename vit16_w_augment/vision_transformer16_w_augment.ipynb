{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import glob, warnings\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from datasets import load_dataset\n",
    "from transformers import ViTFeatureExtractor, AutoModelForImageClassification, AutoFeatureExtractor, ViTForImageClassification\n",
    "from datasets import load_metric\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "try:\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "     \n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf8d7657c3e444597884a31773666ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration train-5ba040123c4f7080\n",
      "Found cached dataset imagefolder (/home/chash345/.cache/huggingface/datasets/imagefolder/train-5ba040123c4f7080/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27af5167b1654e35bf5805178e11c502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45463a767804d95b53580bd1eaa25d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration valid-1603420759c35bdb\n",
      "Found cached dataset imagefolder (/home/chash345/.cache/huggingface/datasets/imagefolder/valid-1603420759c35bdb/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3db70c3089245df8f05a1dc65b00cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e580cac72e904d89b67ae00ab2612110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration test-1f68a239285f9c45\n",
      "Found cached dataset imagefolder (/home/chash345/.cache/huggingface/datasets/imagefolder/test-1f68a239285f9c45/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd60eb845c244629a32768f1438480cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = load_dataset('/local/data1/chash345/train')\n",
    "valid = load_dataset('/local/data1/chash345/valid')\n",
    "test = load_dataset('/local/data1/chash345/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2080"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(train['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=2990x2990>,\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['train'][2555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTFeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"size\": 224\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_feature = feature_extractor(\n",
    "    train['train'][100]['image'],\n",
    "    return_tensors = 'pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_feature['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import (CenterCrop, \n",
    "                                    Compose, \n",
    "                                    Normalize, \n",
    "                                    RandomHorizontalFlip,\n",
    "                                    RandomResizedCrop, \n",
    "                                    Resize, \n",
    "                                    ToTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "_train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(feature_extractor.size),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "_val_transforms = Compose(\n",
    "        [\n",
    "            Resize(feature_extractor.size),\n",
    "            CenterCrop(feature_extractor.size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "_test_transforms = Compose(\n",
    "        [\n",
    "            Resize(feature_extractor.size),\n",
    "            CenterCrop(feature_extractor.size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def train_transforms(examples):\n",
    "    examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples\n",
    "\n",
    "def val_transforms(examples):\n",
    "    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples\n",
    "\n",
    "def test_transforms(examples):\n",
    "    examples['pixel_values'] = [_test_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'transform'=<function train_transforms at 0x7faa847a7d30> of the transform datasets.arrow_dataset.Dataset.set_format couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "prepared_train = train['train'].with_transform(train_transforms)\n",
    "prepared_valid = valid['train'].with_transform(val_transforms)\n",
    "prepared_test = test['train'].with_transform(test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 2600\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 870\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 864\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(batch):\n",
    "#     inputs = feature_extractor(\n",
    "#         batch['image'],\n",
    "#         return_tensors = 'pt'\n",
    "#     ).to(device)\n",
    "\n",
    "#     inputs['label'] = batch['label']\n",
    "\n",
    "#     return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return{\n",
    "        'pixel_values':torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['label'] for x in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric('accuracy')\n",
    "\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(\n",
    "        predictions = np.argmax(p.predictions, axis=1),\n",
    "        references = p.label_ids\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= '/local/data1/chash345/Vision-Transformer-Research-Project/vit16_w_augment',\n",
    "    seed=100,\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy='steps',\n",
    "    num_train_epochs=15,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    load_best_model_at_end=True,\n",
    "    dataloader_pin_memory=False\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "labels = train['train']['label']\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels = len(labels)\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_train,\n",
    "    eval_dataset=prepared_valid,\n",
    "    tokenizer=feature_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2600\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 815\n",
      "  Number of trainable parameters = 87798056\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='815' max='815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [815/815 2:27:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.708800</td>\n",
       "      <td>0.657291</td>\n",
       "      <td>0.798851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.429700</td>\n",
       "      <td>0.492501</td>\n",
       "      <td>0.808046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.542700</td>\n",
       "      <td>0.493088</td>\n",
       "      <td>0.798851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.298600</td>\n",
       "      <td>0.426059</td>\n",
       "      <td>0.832184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.396225</td>\n",
       "      <td>0.840230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.440261</td>\n",
       "      <td>0.855172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.498598</td>\n",
       "      <td>0.850575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.503367</td>\n",
       "      <td>0.845977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-100\n",
      "Configuration saved in ../checkpoint-100/config.json\n",
      "Model weights saved in ../checkpoint-100/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-100/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-200\n",
      "Configuration saved in ../checkpoint-200/config.json\n",
      "Model weights saved in ../checkpoint-200/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-200/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-300\n",
      "Configuration saved in ../checkpoint-300/config.json\n",
      "Model weights saved in ../checkpoint-300/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-300/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-400\n",
      "Configuration saved in ../checkpoint-400/config.json\n",
      "Model weights saved in ../checkpoint-400/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-400/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-500\n",
      "Configuration saved in ../checkpoint-500/config.json\n",
      "Model weights saved in ../checkpoint-500/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-500/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-600\n",
      "Configuration saved in ../checkpoint-600/config.json\n",
      "Model weights saved in ../checkpoint-600/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-600/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-700\n",
      "Configuration saved in ../checkpoint-700/config.json\n",
      "Model weights saved in ../checkpoint-700/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-700/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-800\n",
      "Configuration saved in ../checkpoint-800/config.json\n",
      "Model weights saved in ../checkpoint-800/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-800/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-700] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../checkpoint-500 (score: 0.3962247371673584).\n",
      "Saving model checkpoint to ../\n",
      "Configuration saved in ../config.json\n",
      "Model weights saved in ../pytorch_model.bin\n",
      "Image processor saved in ../preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =         5.0\n",
      "  total_flos               = 960056791GF\n",
      "  train_loss               =       0.608\n",
      "  train_runtime            =  2:27:38.94\n",
      "  train_samples_per_second =       1.467\n",
      "  train_steps_per_second   =       0.092\n"
     ]
    }
   ],
   "source": [
    "model_results = trainer.train()\n",
    "\n",
    "trainer.save_model()\n",
    "trainer.log_metrics('train', model_results.metrics)\n",
    "trainer.save_metrics('train', model_results.metrics)\n",
    "\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the test accuracy is around 86% when we use Vision tranformer with 16 patches. Next, we will try different vit architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at /local/data1/chash345/Vision-Transformer-Research-Project/vit16_w_augment and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2600, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2600]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ViTForImageClassification.from_pretrained('/local/data1/chash345/Vision-Transformer-Research-Project/vit16_w_augment', \n",
    "num_labels=2, \n",
    "ignore_mismatched_sizes=True).to('cuda')\n",
    "\n",
    "    \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= '/local/data1/chash345/Vision-Transformer-Research-Project/vit16_w_augment',\n",
    "    seed=100,\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    load_best_model_at_end=True,\n",
    "    do_predict=True,\n",
    "    dataloader_pin_memory=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=feature_extractor,\n",
    "    eval_dataset= prepared_test\n",
    ")\n",
    "#trainer = Trainer(model=model)\n",
    "#trainer.model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 864\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction_test = trainer.predict(prepared_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.11236042,  0.3102383 ],\n",
       "       [-0.00555236,  0.3285576 ],\n",
       "       [ 0.09415171,  0.31086984],\n",
       "       ...,\n",
       "       [ 0.08107684,  0.29746634],\n",
       "       [ 0.03203754,  0.34434456],\n",
       "       [ 0.00197087,  0.3332291 ]], dtype=float32), label_ids=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1]), metrics={'test_loss': 0.6070970892906189, 'test_accuracy': 0.7997685185185185, 'test_runtime': 140.5389, 'test_samples_per_second': 6.148, 'test_steps_per_second': 0.768})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = np.argmax(prediction_test.predictions, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test['train']['label']\n",
    "y_pred = prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 173],\n",
       "       [  0, 691]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true= y_true , y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.908397</td>\n",
       "      <td>0.687861</td>\n",
       "      <td>0.782895</td>\n",
       "      <td>173.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.926330</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>0.953652</td>\n",
       "      <td>691.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.923611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.917364</td>\n",
       "      <td>0.835248</td>\n",
       "      <td>0.868273</td>\n",
       "      <td>864.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.922739</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.919461</td>\n",
       "      <td>864.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.908397  0.687861  0.782895  173.000000\n",
       "1              0.926330  0.982634  0.953652  691.000000\n",
       "accuracy       0.923611  0.923611  0.923611    0.923611\n",
       "macro avg      0.917364  0.835248  0.868273  864.000000\n",
       "weighted avg   0.922739  0.923611  0.919461  864.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay, auc\n",
    "\n",
    "# %%\n",
    "fpr, tpr, thresholds = roc_curve(y_true, prediction_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8352475678207841"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "roc_auc_score(y_true , prediction_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "display = RocCurveDisplay(fpr=fpr,tpr=tpr, roc_auc=roc_auc)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
