{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 21:46:46.139537: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import glob, warnings\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from datasets import load_dataset\n",
    "from transformers import ViTFeatureExtractor, AutoModelForImageClassification, AutoFeatureExtractor\n",
    "from datasets import load_metric\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "try:\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "     \n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acaf5006334d4d9883181a83108d47b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration train-5ba040123c4f7080\n",
      "Found cached dataset imagefolder (/home/chash345/.cache/huggingface/datasets/imagefolder/train-5ba040123c4f7080/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282f9cd7867e46c78cd7697fc7892527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8e9c6b622140ce956cfbf641d85768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration valid-1603420759c35bdb\n",
      "Found cached dataset imagefolder (/home/chash345/.cache/huggingface/datasets/imagefolder/valid-1603420759c35bdb/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c35fd0315984827944b116f837c6db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580fb8586aab4020a7c22a659ce30671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration test-1f68a239285f9c45\n",
      "Found cached dataset imagefolder (/home/chash345/.cache/huggingface/datasets/imagefolder/test-1f68a239285f9c45/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b836ebedc3104748bedbadd6536b12fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = load_dataset('/local/data1/chash345/train')\n",
    "valid = load_dataset('/local/data1/chash345/valid')\n",
    "test = load_dataset('/local/data1/chash345/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2080"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(train['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=2990x2990>,\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['train'][2555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTFeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"size\": 224\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_feature = feature_extractor(\n",
    "    train['train'][100]['image'],\n",
    "    return_tensors = 'pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_feature['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import (CenterCrop, \n",
    "                                    Compose, \n",
    "                                    Normalize, \n",
    "                                    RandomHorizontalFlip,\n",
    "                                    RandomResizedCrop, \n",
    "                                    Resize, \n",
    "                                    ToTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "_train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(feature_extractor.size),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "_val_transforms = Compose(\n",
    "        [\n",
    "            Resize(feature_extractor.size),\n",
    "            CenterCrop(feature_extractor.size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "_test_transforms = Compose(\n",
    "        [\n",
    "            Resize(feature_extractor.size),\n",
    "            CenterCrop(feature_extractor.size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def train_transforms(examples):\n",
    "    examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples\n",
    "\n",
    "def val_transforms(examples):\n",
    "    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples\n",
    "\n",
    "def test_transforms(examples):\n",
    "    examples['pixel_values'] = [_test_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'transform'=<function train_transforms at 0x7faa9f790940> of the transform datasets.arrow_dataset.Dataset.set_format couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "prepared_train = train['train'].with_transform(train_transforms)\n",
    "prepared_valid = valid['train'].with_transform(val_transforms)\n",
    "prepared_test = test['train'].with_transform(test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 2600\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 870\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 864\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(batch):\n",
    "#     inputs = feature_extractor(\n",
    "#         batch['image'],\n",
    "#         return_tensors = 'pt'\n",
    "#     ).to(device)\n",
    "\n",
    "#     inputs['label'] = batch['label']\n",
    "\n",
    "#     return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return{\n",
    "        'pixel_values':torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['label'] for x in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric('accuracy')\n",
    "\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(\n",
    "        predictions = np.argmax(p.predictions, axis=1),\n",
    "        references = p.label_ids\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= '/local/data1/chash345/Vision-Transformer-Research-Project/vit16_w_augment',\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy='steps',\n",
    "    num_train_epochs=10,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "labels = train['train']['label']\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels = len(labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_train,\n",
    "    eval_dataset=prepared_valid,\n",
    "    tokenizer=feature_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2600\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 815\n",
      "  Number of trainable parameters = 87798056\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='815' max='815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [815/815 2:27:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.708800</td>\n",
       "      <td>0.657291</td>\n",
       "      <td>0.798851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.429700</td>\n",
       "      <td>0.492501</td>\n",
       "      <td>0.808046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.542700</td>\n",
       "      <td>0.493088</td>\n",
       "      <td>0.798851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.298600</td>\n",
       "      <td>0.426059</td>\n",
       "      <td>0.832184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.396225</td>\n",
       "      <td>0.840230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.440261</td>\n",
       "      <td>0.855172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.498598</td>\n",
       "      <td>0.850575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.503367</td>\n",
       "      <td>0.845977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-100\n",
      "Configuration saved in ../checkpoint-100/config.json\n",
      "Model weights saved in ../checkpoint-100/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-100/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-200\n",
      "Configuration saved in ../checkpoint-200/config.json\n",
      "Model weights saved in ../checkpoint-200/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-200/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-300\n",
      "Configuration saved in ../checkpoint-300/config.json\n",
      "Model weights saved in ../checkpoint-300/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-300/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-400\n",
      "Configuration saved in ../checkpoint-400/config.json\n",
      "Model weights saved in ../checkpoint-400/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-400/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-500\n",
      "Configuration saved in ../checkpoint-500/config.json\n",
      "Model weights saved in ../checkpoint-500/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-500/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-600\n",
      "Configuration saved in ../checkpoint-600/config.json\n",
      "Model weights saved in ../checkpoint-600/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-600/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-700\n",
      "Configuration saved in ../checkpoint-700/config.json\n",
      "Model weights saved in ../checkpoint-700/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-700/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-800\n",
      "Configuration saved in ../checkpoint-800/config.json\n",
      "Model weights saved in ../checkpoint-800/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-800/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-700] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../checkpoint-500 (score: 0.3962247371673584).\n",
      "Saving model checkpoint to ../\n",
      "Configuration saved in ../config.json\n",
      "Model weights saved in ../pytorch_model.bin\n",
      "Image processor saved in ../preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =         5.0\n",
      "  total_flos               = 960056791GF\n",
      "  train_loss               =       0.608\n",
      "  train_runtime            =  2:27:38.94\n",
      "  train_samples_per_second =       1.467\n",
      "  train_steps_per_second   =       0.092\n"
     ]
    }
   ],
   "source": [
    "model_results = trainer.train()\n",
    "\n",
    "trainer.save_model()\n",
    "trainer.log_metrics('train', model_results.metrics)\n",
    "trainer.save_metrics('train', model_results.metrics)\n",
    "\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the test accuracy is around 86% when we use Vision tranformer with 16 patches. Next, we will try different vit architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /local/data1/chash345/vit16w_augment_model/checkpoint-1200/config.json\n",
      "Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224-in21k\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qkv_bias\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\"\n",
      "}\n",
      "\n",
      "loading weights file /local/data1/chash345/vit16w_augment_model/checkpoint-1200/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ViTForImageClassification.\n",
      "\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at /local/data1/chash345/vit16w_augment_model/checkpoint-1200 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2600, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2600]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "using `logging_steps` to initialize `eval_steps` to 500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 864\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ViTForImageClassification.from_pretrained('/local/data1/chash345/vit16w_augment_model/checkpoint-1200', num_labels=2, ignore_mismatched_sizes=True )\n",
    "\n",
    "    \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= '/local/data1/chash345/vit16_w_augment_model/checkpoint-1200',\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    load_best_model_at_end=True,\n",
    "    do_predict=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=feature_extractor,\n",
    ")\n",
    "#trainer = Trainer(model=model)\n",
    "#trainer.model = model.cuda()\n",
    "prediction_test = trainer.predict(prepared_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.19684175,  0.15582417],\n",
       "       [-0.23898914,  0.12191474],\n",
       "       [-0.20743626,  0.17989267],\n",
       "       ...,\n",
       "       [-0.22876006,  0.19378911],\n",
       "       [-0.216553  ,  0.04672924],\n",
       "       [-0.22859126,  0.05223001]], dtype=float32), label_ids=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1]), metrics={'test_loss': 0.6159340143203735, 'test_accuracy': 0.7997685185185185, 'test_runtime': 246.1244, 'test_samples_per_second': 3.51, 'test_steps_per_second': 0.439})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 15:34:51.200668: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-12-22 15:34:51.204708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-12-22 15:34:51.222843: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-12-22 15:34:51.222918: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: lnx00273.ad.liu.se\n",
      "2022-12-22 15:34:51.222936: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: lnx00273.ad.liu.se\n",
      "2022-12-22 15:34:51.223102: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.60.11\n",
      "2022-12-22 15:34:51.223184: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.60.11\n",
      "2022-12-22 15:34:51.223201: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.60.11\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Hide GPU from visible devices\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 15:34:52.883514: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 15:34:52.884023: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "prediction = tf.round(tf.nn.sigmoid(prediction_test.predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction\n",
    "prediction_test = np.argmax(prediction, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test['train']['label']\n",
    "y_pred = prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 173],\n",
       "       [  3, 688]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true= y_true , y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>173.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.799071</td>\n",
       "      <td>0.995658</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>691.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.796296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.399535</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>0.443299</td>\n",
       "      <td>864.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.639072</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.709073</td>\n",
       "      <td>864.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.000000  0.000000  0.000000  173.000000\n",
       "1              0.799071  0.995658  0.886598  691.000000\n",
       "accuracy       0.796296  0.796296  0.796296    0.796296\n",
       "macro avg      0.399535  0.497829  0.443299  864.000000\n",
       "weighted avg   0.639072  0.796296  0.709073  864.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay, auc\n",
    "\n",
    "# %%\n",
    "fpr, tpr, thresholds = roc_curve(y_true, prediction_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49782923299565845"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "roc_auc_score(y_true , prediction_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "display = RocCurveDisplay(fpr=fpr,tpr=tpr, roc_auc=roc_auc)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researchkernel",
   "language": "python",
   "name": "researchkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24745f2cfe87266a2e3f1c3bc0099ef3874c0fb00fd483dd9f076f273543ffa9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
