{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 22:05:44.488738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import glob, warnings\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from datasets import load_dataset\n",
    "from transformers import ViTFeatureExtractor, AutoModelForImageClassification\n",
    "from datasets import load_metric\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "try:\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "     \n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fd0b113a144d009191bf85819349a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration train-5ba040123c4f7080\n",
      "Found cached dataset imagefolder (/home/chash345/.cache/huggingface/datasets/imagefolder/train-5ba040123c4f7080/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff738b681af4380a346e49b5872ef9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca8de2219e54a80abaf7a133b8fed51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration valid-1603420759c35bdb\n",
      "Found cached dataset imagefolder (/home/chash345/.cache/huggingface/datasets/imagefolder/valid-1603420759c35bdb/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d1909c6bfd450399547f287e6d733d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6023a64dccf49ec8d83ce5334b76024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration test-1f68a239285f9c45\n",
      "Found cached dataset imagefolder (/home/chash345/.cache/huggingface/datasets/imagefolder/test-1f68a239285f9c45/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee931af1cd34091828d40df793c9aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = load_dataset('/local/data1/chash345/train')\n",
    "valid = load_dataset('/local/data1/chash345/valid')\n",
    "test = load_dataset('/local/data1/chash345/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2080"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(train['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=2990x2990>,\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['train'][2555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTFeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"size\": 224\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_or_path = 'google/vit-base-patch32-224-in21k'\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_feature = feature_extractor(\n",
    "    train['train'][100]['image'],\n",
    "    return_tensors = 'pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.]]]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_feature['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.FloatTensor([0., 1., 2.])\n",
    "X_train.is_cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'transform'=<function train_transforms at 0x7f7c48394550> of the transform datasets.arrow_dataset.Dataset.set_format couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 864\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.transforms import (CenterCrop, \n",
    "                                    Compose, \n",
    "                                    Normalize, \n",
    "                                    RandomHorizontalFlip,\n",
    "                                    RandomResizedCrop, \n",
    "                                    Resize, \n",
    "                                    ToTensor)\n",
    "\n",
    "# %%\n",
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "_train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(feature_extractor.size),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "_val_transforms = Compose(\n",
    "        [\n",
    "            Resize(feature_extractor.size),\n",
    "            CenterCrop(feature_extractor.size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "_test_transforms = Compose(\n",
    "        [\n",
    "            Resize(feature_extractor.size),\n",
    "            CenterCrop(feature_extractor.size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def train_transforms(examples):\n",
    "    examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples\n",
    "\n",
    "def val_transforms(examples):\n",
    "    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples\n",
    "\n",
    "def test_transforms(examples):\n",
    "    examples['pixel_values'] = [_test_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples\n",
    "\n",
    "# %%\n",
    "prepared_train = train['train'].with_transform(train_transforms)\n",
    "prepared_valid = valid['train'].with_transform(val_transforms)\n",
    "prepared_test = test['train'].with_transform(test_transforms)\n",
    "\n",
    "# %%\n",
    "prepared_train\n",
    "\n",
    "# %%\n",
    "prepared_valid\n",
    "\n",
    "# %%\n",
    "prepared_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepared_test.set_format(type=prepared_test.format[\"type\"], columns=list(prepared_test.features.keys()), transform= preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return{\n",
    "        'pixel_values':torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['label'] for x in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric('accuracy')\n",
    "\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(\n",
    "        predictions = np.argmax(p.predictions, axis=1),\n",
    "        references = p.label_ids\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= '/local/data1/chash345/vit32_w_augment_model',\n",
    "    seed=100,\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy='steps',\n",
    "    num_train_epochs=25,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    load_best_model_at_end=True,\n",
    "    dataloader_pin_memory=False\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch32-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch32-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "labels = train['train']['label']\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels = len(labels)\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_train,\n",
    "    eval_dataset=prepared_valid,\n",
    "    tokenizer=feature_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2600\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 815\n",
      "  Number of trainable parameters = 87798056\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='815' max='815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [815/815 2:27:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.708800</td>\n",
       "      <td>0.657291</td>\n",
       "      <td>0.798851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.429700</td>\n",
       "      <td>0.492501</td>\n",
       "      <td>0.808046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.542700</td>\n",
       "      <td>0.493088</td>\n",
       "      <td>0.798851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.298600</td>\n",
       "      <td>0.426059</td>\n",
       "      <td>0.832184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.396225</td>\n",
       "      <td>0.840230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.440261</td>\n",
       "      <td>0.855172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.498598</td>\n",
       "      <td>0.850575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.503367</td>\n",
       "      <td>0.845977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-100\n",
      "Configuration saved in ../checkpoint-100/config.json\n",
      "Model weights saved in ../checkpoint-100/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-100/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-200\n",
      "Configuration saved in ../checkpoint-200/config.json\n",
      "Model weights saved in ../checkpoint-200/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-200/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-300\n",
      "Configuration saved in ../checkpoint-300/config.json\n",
      "Model weights saved in ../checkpoint-300/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-300/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-400\n",
      "Configuration saved in ../checkpoint-400/config.json\n",
      "Model weights saved in ../checkpoint-400/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-400/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-500\n",
      "Configuration saved in ../checkpoint-500/config.json\n",
      "Model weights saved in ../checkpoint-500/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-500/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-600\n",
      "Configuration saved in ../checkpoint-600/config.json\n",
      "Model weights saved in ../checkpoint-600/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-600/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-700\n",
      "Configuration saved in ../checkpoint-700/config.json\n",
      "Model weights saved in ../checkpoint-700/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-700/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../checkpoint-800\n",
      "Configuration saved in ../checkpoint-800/config.json\n",
      "Model weights saved in ../checkpoint-800/pytorch_model.bin\n",
      "Image processor saved in ../checkpoint-800/preprocessor_config.json\n",
      "Deleting older checkpoint [../checkpoint-700] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../checkpoint-500 (score: 0.3962247371673584).\n",
      "Saving model checkpoint to ../\n",
      "Configuration saved in ../config.json\n",
      "Model weights saved in ../pytorch_model.bin\n",
      "Image processor saved in ../preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =         5.0\n",
      "  total_flos               = 960056791GF\n",
      "  train_loss               =       0.608\n",
      "  train_runtime            =  2:27:38.94\n",
      "  train_samples_per_second =       1.467\n",
      "  train_steps_per_second   =       0.092\n"
     ]
    }
   ],
   "source": [
    "model_results = trainer.train()\n",
    "\n",
    "trainer.save_model()\n",
    "trainer.log_metrics('train', model_results.metrics)\n",
    "trainer.save_metrics('train', model_results.metrics)\n",
    "\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /local/data1/chash345/vit32_w_augment_model/checkpoint-4000/config.json\n",
      "Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch32-224-in21k\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 32,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qkv_bias\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\"\n",
      "}\n",
      "\n",
      "loading weights file /local/data1/chash345/vit32_w_augment_model/checkpoint-4000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ViTForImageClassification.\n",
      "\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at /local/data1/chash345/vit32_w_augment_model/checkpoint-4000 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2600, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2600]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "using `logging_steps` to initialize `eval_steps` to 500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 864\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ViTForImageClassification.from_pretrained('/local/data1/chash345/vit32_w_augment_model/checkpoint-4000', num_labels=2, ignore_mismatched_sizes=True ).to('cuda')\n",
    "\n",
    "    \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= '/local/data1/chash345/vit32_w_augment_model/',\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    load_best_model_at_end=True,\n",
    "    do_predict=True,\n",
    "    dataloader_pin_memory=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=feature_extractor,\n",
    "    eval_dataset=prepared_test\n",
    ")\n",
    "#trainer = Trainer(model=model)\n",
    "#trainer.model = model.cuda()\n",
    "prediction_test = trainer.predict(prepared_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[0.01596877, 0.13878164],\n",
       "       [0.03614973, 0.1485546 ],\n",
       "       [0.00985433, 0.14106196],\n",
       "       ...,\n",
       "       [0.03392009, 0.14468339],\n",
       "       [0.08698587, 0.10839661],\n",
       "       [0.074837  , 0.11146569]], dtype=float32), label_ids=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1]), metrics={'test_loss': 0.6712297797203064, 'test_accuracy': 0.8009259259259259, 'test_runtime': 121.4764, 'test_samples_per_second': 7.112, 'test_steps_per_second': 0.889})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_test = np.argmax(prediction_test.predictions, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test['train']['label']\n",
    "y_pred = prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2, 171],\n",
       "       [  1, 690]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true= y_true , y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>173.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.801394</td>\n",
       "      <td>0.998553</td>\n",
       "      <td>0.889175</td>\n",
       "      <td>691.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.800926</td>\n",
       "      <td>0.800926</td>\n",
       "      <td>0.800926</td>\n",
       "      <td>0.800926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.734030</td>\n",
       "      <td>0.505057</td>\n",
       "      <td>0.455951</td>\n",
       "      <td>864.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.774417</td>\n",
       "      <td>0.800926</td>\n",
       "      <td>0.715685</td>\n",
       "      <td>864.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.666667  0.011561  0.022727  173.000000\n",
       "1              0.801394  0.998553  0.889175  691.000000\n",
       "accuracy       0.800926  0.800926  0.800926    0.800926\n",
       "macro avg      0.734030  0.505057  0.455951  864.000000\n",
       "weighted avg   0.774417  0.800926  0.715685  864.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay, auc\n",
    "\n",
    "# %%\n",
    "fpr, tpr, thresholds = roc_curve(y_true, prediction_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5050567578193621"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "roc_auc_score(y_true , prediction_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "display = RocCurveDisplay(fpr=fpr,tpr=tpr, roc_auc=roc_auc)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
