{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 10:06:10.569956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50  import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.resnet import ResNet152\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 10:06:17.695721: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-23 10:06:17.697858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-23 10:06:17.728983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 10:06:17.729135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 3060 Ti computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 38 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-11-23 10:06:17.729156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-23 10:06:17.750381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-23 10:06:17.750425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-11-23 10:06:17.762373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-23 10:06:17.784145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-23 10:06:17.803279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-11-23 10:06:17.814363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-11-23 10:06:17.829645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-23 10:06:17.829838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 10:06:17.830089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 10:06:17.830224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore FutureWarning from numpy\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "\n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";\n",
    "\n",
    "# Allow growth of GPU memory, otherwise it will always look like all the memory is being used\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagenerator = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=30,\n",
    "    vertical_flip=False,\n",
    "    brightness_range=[0.90,1.25],\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2600 images belonging to 2 classes.\n",
      "Found 870 images belonging to 2 classes.\n",
      "Found 864 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# load and iterate training dataset\n",
    "train_data = datagenerator.flow_from_directory('../train/', \n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224), \n",
    "    batch_size=32, \n",
    "    shuffle=False)\n",
    "\n",
    "# load and iterate validation dataset\n",
    "val_data = datagenerator.flow_from_directory('../valid/', \n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32, \n",
    "    shuffle=True)\n",
    "\n",
    "# load and iterate test dataset\n",
    "test_data = datagenerator.flow_from_directory('../test/', \n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32, \n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.activations import relu, softmax, sigmoid, swish\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 10:06:18.285331: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-23 10:06:18.285795: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-23 10:06:18.286054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 10:06:18.286412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 3060 Ti computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 38 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-11-23 10:06:18.286481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-23 10:06:18.286535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-23 10:06:18.286580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-11-23 10:06:18.286619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-23 10:06:18.286654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-23 10:06:18.286693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-11-23 10:06:18.286732: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-11-23 10:06:18.286770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-23 10:06:18.286912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 10:06:18.287292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 10:06:18.287560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-11-23 10:06:18.287633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pre_trained_model_resnet152 \u001b[39m=\u001b[39m ResNet152(input_shape\u001b[39m=\u001b[39;49m(\u001b[39m224\u001b[39;49m,\u001b[39m224\u001b[39;49m,\u001b[39m3\u001b[39;49m),\n\u001b[1;32m      2\u001b[0m                                 include_top\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      3\u001b[0m                                 weights\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/keras/applications/resnet.py:513\u001b[0m, in \u001b[0;36mResNet152\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m   x \u001b[39m=\u001b[39m stack1(x, \u001b[39m256\u001b[39m, \u001b[39m36\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconv4\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    511\u001b[0m   \u001b[39mreturn\u001b[39;00m stack1(x, \u001b[39m512\u001b[39m, \u001b[39m3\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconv5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 513\u001b[0m \u001b[39mreturn\u001b[39;00m ResNet(stack_fn, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39m'\u001b[39;49m\u001b[39mresnet152\u001b[39;49m\u001b[39m'\u001b[39;49m, include_top, weights,\n\u001b[1;32m    514\u001b[0m               input_tensor, input_shape, pooling, classes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/keras/applications/resnet.py:168\u001b[0m, in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m bn_axis \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39mimage_data_format() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mchannels_last\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    166\u001b[0m x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mZeroPadding2D(\n\u001b[1;32m    167\u001b[0m     padding\u001b[39m=\u001b[39m((\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m)), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconv1_pad\u001b[39m\u001b[39m'\u001b[39m)(img_input)\n\u001b[0;32m--> 168\u001b[0m x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m64\u001b[39;49m, \u001b[39m7\u001b[39;49m, strides\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, use_bias\u001b[39m=\u001b[39;49muse_bias, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv1_conv\u001b[39;49m\u001b[39m'\u001b[39;49m)(x)\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m preact:\n\u001b[1;32m    171\u001b[0m   x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mBatchNormalization(\n\u001b[1;32m    172\u001b[0m       axis\u001b[39m=\u001b[39mbn_axis, epsilon\u001b[39m=\u001b[39m\u001b[39m1.001e-5\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconv1_bn\u001b[39m\u001b[39m'\u001b[39m)(x)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:951\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 951\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m    952\u001b[0m                                             input_list)\n\u001b[1;32m    954\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    955\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1090\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[39mif\u001b[39;00m keras_tensor\u001b[39m.\u001b[39mkeras_tensors_enabled():\n\u001b[1;32m   1087\u001b[0m   \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[1;32m   1088\u001b[0m       layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value):\n\u001b[1;32m   1089\u001b[0m     \u001b[39m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 1090\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[1;32m   1091\u001b[0m         inputs, input_masks, args, kwargs)\n\u001b[1;32m   1093\u001b[0m     \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1095\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1096\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:822\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mmap_structure(keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m    821\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 822\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:862\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39mwith\u001b[39;00m backend\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name_scope()):\n\u001b[1;32m    857\u001b[0m   \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    858\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# overridden).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_build(inputs)\n\u001b[1;32m    863\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    865\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2710\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2705\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild, \u001b[39m'\u001b[39m\u001b[39m_is_default\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   2706\u001b[0m   \u001b[39m# Any setup work performed only once should happen in an `init_scope`\u001b[39;00m\n\u001b[1;32m   2707\u001b[0m   \u001b[39m# to avoid creating symbolic Tensors that will later pollute any eager\u001b[39;00m\n\u001b[1;32m   2708\u001b[0m   \u001b[39m# operations.\u001b[39;00m\n\u001b[1;32m   2709\u001b[0m   \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mmaybe_init_scope(\u001b[39mself\u001b[39m):\n\u001b[0;32m-> 2710\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild(input_shapes)  \u001b[39m# pylint:disable=not-callable\u001b[39;00m\n\u001b[1;32m   2711\u001b[0m \u001b[39m# We must set also ensure that the layer is marked as built, and the build\u001b[39;00m\n\u001b[1;32m   2712\u001b[0m \u001b[39m# shape is stored since user defined build functions may not be calling\u001b[39;00m\n\u001b[1;32m   2713\u001b[0m \u001b[39m# `super.build()`\u001b[39;00m\n\u001b[1;32m   2714\u001b[0m Layer\u001b[39m.\u001b[39mbuild(\u001b[39mself\u001b[39m, input_shapes)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py:198\u001b[0m, in \u001b[0;36mConv.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    190\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mThe number of input channels must be evenly divisible by the number \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    192\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mof groups. Received groups=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, but the input has \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m channels \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    193\u001b[0m       \u001b[39m'\u001b[39m\u001b[39m(full input shape is \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups, input_channel,\n\u001b[1;32m    194\u001b[0m                                          input_shape))\n\u001b[1;32m    195\u001b[0m kernel_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size \u001b[39m+\u001b[39m (input_channel \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[1;32m    196\u001b[0m                                    \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters)\n\u001b[0;32m--> 198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_weight(\n\u001b[1;32m    199\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mkernel\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    200\u001b[0m     shape\u001b[39m=\u001b[39;49mkernel_shape,\n\u001b[1;32m    201\u001b[0m     initializer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_initializer,\n\u001b[1;32m    202\u001b[0m     regularizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_regularizer,\n\u001b[1;32m    203\u001b[0m     constraint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_constraint,\n\u001b[1;32m    204\u001b[0m     trainable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    205\u001b[0m     dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)\n\u001b[1;32m    206\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\n\u001b[1;32m    208\u001b[0m       name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    209\u001b[0m       shape\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m       trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    214\u001b[0m       dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:623\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m     tf_logging\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`caching_device` does not work with mixed precision \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    620\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mAPI. Ignoring user specified `caching_device`.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    621\u001b[0m     caching_device \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 623\u001b[0m variable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_variable_with_custom_getter(\n\u001b[1;32m    624\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    625\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39m# `Trackable` method.\u001b[39;49;00m\n\u001b[1;32m    628\u001b[0m     getter\u001b[39m=\u001b[39;49mgetter,\n\u001b[1;32m    629\u001b[0m     \u001b[39m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[1;32m    630\u001b[0m     overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    631\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    632\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    633\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    634\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    635\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    636\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections_arg,\n\u001b[1;32m    637\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    638\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[1;32m    639\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device)\n\u001b[1;32m    640\u001b[0m \u001b[39mif\u001b[39;00m regularizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m   \u001b[39m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[1;32m    642\u001b[0m   \u001b[39m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[1;32m    643\u001b[0m   \u001b[39m# should be variable attributes.\u001b[39;00m\n\u001b[1;32m    644\u001b[0m   name_in_scope \u001b[39m=\u001b[39m variable\u001b[39m.\u001b[39mname[:variable\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:805\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    795\u001b[0m   \u001b[39mif\u001b[39;00m (checkpoint_initializer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    796\u001b[0m       \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    797\u001b[0m            (initializer\u001b[39m.\u001b[39mrestore_uid \u001b[39m>\u001b[39m checkpoint_initializer\u001b[39m.\u001b[39mrestore_uid))):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[39m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     \u001b[39m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[1;32m    804\u001b[0m     initializer \u001b[39m=\u001b[39m checkpoint_initializer\n\u001b[0;32m--> 805\u001b[0m new_variable \u001b[39m=\u001b[39m getter(\n\u001b[1;32m    806\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    807\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    808\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    809\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    810\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_for_getter)\n\u001b[1;32m    812\u001b[0m \u001b[39m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[39m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[39m# handles slot variables.\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_utils.py:130\u001b[0m, in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m# TODO(apassos,rohanj) figure out how to remove collections from here so we\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m# can remove the V1.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m variable_shape \u001b[39m=\u001b[39m tensor_shape\u001b[39m.\u001b[39mTensorShape(shape)\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m tf_variables\u001b[39m.\u001b[39;49mVariableV1(\n\u001b[1;32m    131\u001b[0m     initial_value\u001b[39m=\u001b[39;49minit_val,\n\u001b[1;32m    132\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    133\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    134\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    135\u001b[0m     dtype\u001b[39m=\u001b[39;49mvariable_dtype,\n\u001b[1;32m    136\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m    137\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    138\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    139\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    140\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    141\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[1;32m    142\u001b[0m     shape\u001b[39m=\u001b[39;49mvariable_shape \u001b[39mif\u001b[39;49;00m variable_shape \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:260\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    259\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m VariableV1:\n\u001b[0;32m--> 260\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_v1_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    261\u001b[0m   \u001b[39melif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m Variable:\n\u001b[1;32m    262\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:206\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m aggregation \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m   aggregation \u001b[39m=\u001b[39m VariableAggregation\u001b[39m.\u001b[39mNONE\n\u001b[0;32m--> 206\u001b[0m \u001b[39mreturn\u001b[39;00m previous_getter(\n\u001b[1;32m    207\u001b[0m     initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[1;32m    208\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    209\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    210\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m    211\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    212\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    213\u001b[0m     variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[1;32m    214\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    215\u001b[0m     expected_shape\u001b[39m=\u001b[39;49mexpected_shape,\n\u001b[1;32m    216\u001b[0m     import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[1;32m    217\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    218\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    219\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    220\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[1;32m    221\u001b[0m     shape\u001b[39m=\u001b[39;49mshape)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:199\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call.<locals>.<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_variable_v1_call\u001b[39m(\u001b[39mcls\u001b[39m,\n\u001b[1;32m    183\u001b[0m                       initial_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    184\u001b[0m                       trainable\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m                       aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE,\n\u001b[1;32m    197\u001b[0m                       shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m   \u001b[39m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m   previous_getter \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: default_variable_creator(\u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m   \u001b[39mfor\u001b[39;00m _, getter \u001b[39min\u001b[39;00m ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39m_variable_creator_stack:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     previous_getter \u001b[39m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py:2604\u001b[0m, in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2602\u001b[0m \u001b[39mif\u001b[39;00m use_resource:\n\u001b[1;32m   2603\u001b[0m   distribute_strategy \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdistribute_strategy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 2604\u001b[0m   \u001b[39mreturn\u001b[39;00m resource_variable_ops\u001b[39m.\u001b[39;49mResourceVariable(\n\u001b[1;32m   2605\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[1;32m   2606\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   2607\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   2608\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m   2609\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   2610\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2611\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   2612\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m   2613\u001b[0m       variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[1;32m   2614\u001b[0m       import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[1;32m   2615\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy,\n\u001b[1;32m   2616\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   2617\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[1;32m   2618\u001b[0m       shape\u001b[39m=\u001b[39;49mshape)\n\u001b[1;32m   2619\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2620\u001b[0m   \u001b[39mreturn\u001b[39;00m variables\u001b[39m.\u001b[39mRefVariable(\n\u001b[1;32m   2621\u001b[0m       initial_value\u001b[39m=\u001b[39minitial_value,\n\u001b[1;32m   2622\u001b[0m       trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2633\u001b[0m       aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[1;32m   2634\u001b[0m       shape\u001b[39m=\u001b[39mshape)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:264\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(VariableMetaclass, \u001b[39mcls\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:1574\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_proto(variable_def, import_scope\u001b[39m=\u001b[39mimport_scope)\n\u001b[1;32m   1573\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1574\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_from_args(\n\u001b[1;32m   1575\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[1;32m   1576\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   1577\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   1578\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   1579\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1580\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1581\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m   1582\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   1583\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[1;32m   1584\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   1585\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:1712\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mInitializer\u001b[39m\u001b[39m\"\u001b[39m), device_context_manager(\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1711\u001b[0m   \u001b[39mif\u001b[39;00m init_from_fn:\n\u001b[0;32m-> 1712\u001b[0m     initial_value \u001b[39m=\u001b[39m initial_value()\n\u001b[1;32m   1713\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(initial_value, trackable\u001b[39m.\u001b[39mCheckpointInitialValue):\n\u001b[1;32m   1714\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/keras/initializers/initializers_v2.py:409\u001b[0m, in \u001b[0;36mVarianceScaling.__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, shape, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    399\u001b[0m   \u001b[39m\"\"\"Returns a tensor object initialized as specified by the initializer.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39m    **kwargs: Additional keyword arguments.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(VarianceScaling, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\n\u001b[1;32m    410\u001b[0m       shape, dtype\u001b[39m=\u001b[39;49m_get_dtype(dtype), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py:600\u001b[0m, in \u001b[0;36mVarianceScaling.__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    599\u001b[0m   limit \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39m3.0\u001b[39m \u001b[39m*\u001b[39m scale)\n\u001b[0;32m--> 600\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_random_generator\u001b[39m.\u001b[39;49mrandom_uniform(shape, \u001b[39m-\u001b[39;49mlimit, limit, dtype)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py:1081\u001b[0m, in \u001b[0;36m_RandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1080\u001b[0m   op \u001b[39m=\u001b[39m random_ops\u001b[39m.\u001b[39mrandom_uniform\n\u001b[0;32m-> 1081\u001b[0m \u001b[39mreturn\u001b[39;00m op(\n\u001b[1;32m   1082\u001b[0m     shape\u001b[39m=\u001b[39;49mshape, minval\u001b[39m=\u001b[39;49mminval, maxval\u001b[39m=\u001b[39;49mmaxval, dtype\u001b[39m=\u001b[39;49mdtype, seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseed)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/ops/random_ops.py:289\u001b[0m, in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m   maxval \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    288\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mrandom_uniform\u001b[39m\u001b[39m\"\u001b[39m, [shape, minval, maxval]) \u001b[39mas\u001b[39;00m name:\n\u001b[0;32m--> 289\u001b[0m   shape \u001b[39m=\u001b[39m tensor_util\u001b[39m.\u001b[39;49mshape_tensor(shape)\n\u001b[1;32m    290\u001b[0m   \u001b[39m# In case of [0,1) floating results, minval and maxval is unused. We do an\u001b[39;00m\n\u001b[1;32m    291\u001b[0m   \u001b[39m# `is` comparison here since this is cheaper than isinstance or  __eq__.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m   minval_is_zero \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(minval, \u001b[39mint\u001b[39m) \u001b[39mand\u001b[39;00m minval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py:1035\u001b[0m, in \u001b[0;36mshape_tensor\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m   1029\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1030\u001b[0m     \u001b[39m# If there are Dimension objects in the shape, unwrap them. This can be a\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m     \u001b[39m# problem if v1 and v2 TensorShape objects get mixed up in partial\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m     \u001b[39m# conversions, leading to shapes such as (1, 2, Dimension(5)), which are\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m     \u001b[39m# not convertible to Tensors because of mixed content.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m     shape \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mmap\u001b[39m(tensor_shape\u001b[39m.\u001b[39mdimension_value, shape))\n\u001b[0;32m-> 1035\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(shape, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mshape\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    162\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1540\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1535\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1536\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1537\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1540\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1542\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1543\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:339\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    337\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    338\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[0;32m--> 339\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:264\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    265\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    275\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 276\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    278\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m    279\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    300\u001b[0m   \u001b[39m\"\"\"Implementation of eager constant.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    302\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:97\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m---> 97\u001b[0m ctx\u001b[39m.\u001b[39;49mensure_initialized()\n\u001b[1;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39mEagerTensor(value, ctx\u001b[39m.\u001b[39mdevice_name, dtype)\n",
      "File \u001b[0;32m~/.conda/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/context.py:526\u001b[0m, in \u001b[0;36mContext.ensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_tfrt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m     pywrap_tfe\u001b[39m.\u001b[39mTFE_ContextOptionsSetTfrt(opts, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_tfrt)\n\u001b[0;32m--> 526\u001b[0m   context_handle \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_NewContext(opts)\n\u001b[1;32m    527\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    528\u001b[0m   pywrap_tfe\u001b[39m.\u001b[39mTFE_DeleteContextOptions(opts)\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "pre_trained_model_resnet152 = ResNet152(input_shape=(224,224,3),\n",
    "                                include_top=False,\n",
    "                                weights=\"imagenet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some weights in later layers are unfreezed\n",
    "for layer in pre_trained_model_resnet152.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "tf.random.set_seed(202)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    pre_trained_model_resnet152,\n",
    "    GlobalAveragePooling2D(),    \n",
    "    Dense(512,activation=\"relu\"),\n",
    "    Dropout(0.4),\n",
    "    Dense(256,activation=\"relu\"),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),  \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=RMSprop(learning_rate=1e-4),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet152 (Functional)       (None, 7, 7, 2048)        58370944  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 59,584,385\n",
      "Trainable params: 1,213,441\n",
      "Non-trainable params: 58,370,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 09:25:49.118635: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-11-23 09:25:49.119683: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3491795000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 09:25:56.116573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-23 09:27:54.443139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-23 09:31:47.499185: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2022-11-23 09:31:47.622313: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 1003s 8s/step - loss: 474122185825824032425252273258496.0000 - accuracy: 0.7364 - val_loss: 0.6910 - val_accuracy: 0.7989\n",
      "Epoch 2/5\n",
      "82/82 [==============================] - 440s 5s/step - loss: 0.6909 - accuracy: 0.7526 - val_loss: 0.6890 - val_accuracy: 0.7989\n",
      "Epoch 3/5\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.8572"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=5,\n",
    "    validation_data=val_data  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 210s 16s/step - loss: 2834.8416 - accuracy: 0.7361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2834.841552734375, 0.7361111044883728]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researchkernel",
   "language": "python",
   "name": "researchkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
